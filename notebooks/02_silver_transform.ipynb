{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8df1043-56db-4589-b03f-bce25d24005a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 02_silver_transform\n",
    "from pyspark.sql.functions import col, when, trim\n",
    "\n",
    "# Use the DB database we created earlier\n",
    "spark.sql(\"USE churn_mlo_mdb\")\n",
    "\n",
    "# Source bronze table created earlier\n",
    "bronze = \"churn_mlo_mdb.bronze_churn\"\n",
    "print(\"Reading bronze table:\", bronze)\n",
    "df = spark.table(bronze)\n",
    "\n",
    "# Quick schema / sanity\n",
    "print(\"Bronze schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# 1) Trim whitespace for string columns (safe)\n",
    "string_cols = [f.name for f in df.schema.fields if f.dataType.simpleString() == \"string\"]\n",
    "for c in string_cols:\n",
    "    df = df.withColumn(c, trim(col(c)))\n",
    "\n",
    "# 2) Fix TotalCharges: empty strings -> null, cast to double\n",
    "df = df.withColumn(\"TotalCharges\", when(col(\"TotalCharges\") == \"\" , None).otherwise(col(\"TotalCharges\").cast(\"double\")))\n",
    "\n",
    "# 3) Drop rows with missing essential keys\n",
    "df = df.dropna(subset=[\"customerID\", \"Churn\"])\n",
    "\n",
    "# 4) Create numeric churn label\n",
    "df = df.withColumn(\"churn_label\", when(col(\"Churn\") == \"Yes\", 1).otherwise(0))\n",
    "\n",
    "# 5) Remove duplicates (if any)\n",
    "df = df.dropDuplicates([\"customerID\"])\n",
    "\n",
    "# 6) Select a stable set of columns for silver (you can expand later)\n",
    "keep_cols = [\"customerID\",\"gender\",\"SeniorCitizen\",\"Partner\",\"Dependents\",\"tenure\",\n",
    "             \"PhoneService\",\"InternetService\",\"MonthlyCharges\",\"TotalCharges\",\n",
    "             \"Contract\",\"PaymentMethod\",\"churn_label\",\"ingestion_time\"]\n",
    "keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "\n",
    "df_silver = df.select(*keep_cols)\n",
    "\n",
    "# 7) Write Silver table as Delta\n",
    "silver_table = \"churn_mlo_mdb.silver_churn\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS churn_mlo_mdb\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {silver_table}\")\n",
    "\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(silver_table)\n",
    "\n",
    "print(\"Silver table created:\", silver_table)\n",
    "display(spark.table(silver_table).limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b00c64-327d-4ba4-850f-a70c0a1545e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_transform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
