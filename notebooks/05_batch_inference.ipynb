{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c5a8e50-874f-49f7-839f-e35aa41479c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 05_batch_inference\n",
    "# Batch scoring using the model stored under MLflow Run ID + writing Gold predictions table\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ------------------------------------\n",
    "# CONFIG â€” UPDATE ONLY THIS IF NEEDED\n",
    "# ------------------------------------\n",
    "RUN_ID = \"cd36fb2b675e4cef86a1e0f1d26fb76c\"   # your last successful run\n",
    "FEATURES_TABLE = \"churn_mlo_mdb.features_churn\"\n",
    "GOLD_TABLE = \"churn_mlo_mdb.gold_predictions\"\n",
    "\n",
    "print(\"Using model from Run ID:\", RUN_ID)\n",
    "print(\"Reading features from:\", FEATURES_TABLE)\n",
    "\n",
    "# ------------------------------------\n",
    "# LOAD FEATURE TABLE (Spark)\n",
    "# ------------------------------------\n",
    "df_features_spark = spark.table(FEATURES_TABLE)\n",
    "print(\"Rows in feature table:\", df_features_spark.count())\n",
    "df_features_spark.display()\n",
    "\n",
    "# Convert to Pandas (safe)\n",
    "pdf = df_features_spark.toPandas()\n",
    "\n",
    "# ------------------------------------\n",
    "# LOAD MODEL FROM MLflow USING RUN ID\n",
    "# ------------------------------------\n",
    "model_uri = f\"runs:/{RUN_ID}/model\"\n",
    "print(\"Loading model from:\", model_uri)\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Prepare X (features)\n",
    "pdf_local = pdf.copy()\n",
    "\n",
    "# Save customer IDs\n",
    "customer_ids = pdf_local[\"customerID\"].astype(str)\n",
    "\n",
    "# Drop columns NOT used during training\n",
    "drop_cols = [\"customerID\", \"churn_label\"]   # exactly like training step\n",
    "for c in drop_cols:\n",
    "    if c in pdf_local.columns:\n",
    "        pdf_local = pdf_local.drop(columns=[c])\n",
    "\n",
    "# Safety fill\n",
    "pdf_local = pdf_local.fillna(0)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Predict churn probability + label\n",
    "# ------------------------------------\n",
    "proba = model.predict_proba(pdf_local)[:, 1]\n",
    "preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Sample predictions:\", list(preds[:10]))\n",
    "print(\"Sample probabilities:\", list(proba[:10]))\n",
    "\n",
    "# ------------------------------------\n",
    "# BUILD OUTPUT DATAFRAME (Detailed)\n",
    "# ------------------------------------\n",
    "pdf_output = pdf.copy()  # keep all features\n",
    "pdf_output[\"churn_probability\"] = proba\n",
    "pdf_output[\"prediction\"] = preds\n",
    "pdf_output[\"run_id\"] = RUN_ID\n",
    "\n",
    "# Convert back to Spark\n",
    "df_gold = spark.createDataFrame(pdf_output)\n",
    "\n",
    "# Add scoring time column\n",
    "df_gold = df_gold.withColumn(\"scoring_timestamp\", current_timestamp())\n",
    "\n",
    "# ------------------------------------\n",
    "# WRITE GOLD TABLE\n",
    "# ------------------------------------\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD_TABLE}\")\n",
    "df_gold.write.format(\"delta\").mode(\"overwrite\").saveAsTable(GOLD_TABLE)\n",
    "\n",
    "print(\"Gold predictions table saved as:\", GOLD_TABLE)\n",
    "\n",
    "display(df_gold.limit(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de578b8c-65ab-4402-b51c-eb284e1caf1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_batch_inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
